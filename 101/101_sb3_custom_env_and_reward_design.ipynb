{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X2jez89FUk_"
      },
      "source": [
        "# Notes\n",
        "\n",
        "MuJoCo environments: https://gymnasium.farama.org/environments/mujoco/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD7W5cyOEmjt"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekllGKpaxhgu"
      },
      "source": [
        "## Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "orm-hmh9xWqT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA_VTiZYI6vP"
      },
      "source": [
        "## Setup - Stable baseline and Gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Install**\n",
        "\n",
        "```bash\n",
        "!pip install numpy matplotlib\n",
        "!pip install gymnaisum\n",
        "!pip install stable_baselines3\n",
        "!pip install tensorboard\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-YOdjdhOWft",
        "outputId": "77854d89-5ba8-4867-c5a4-316e62687af4"
      },
      "outputs": [],
      "source": [
        "# !pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0iYf6MyOiAL",
        "outputId": "25d8c7ef-9488-44db-d68b-149bca349399"
      },
      "outputs": [],
      "source": [
        "# !pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q11TKKM1El_S"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import os\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from stable_baselines3 import SAC, TD3, A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fF1fz53cB21g"
      },
      "outputs": [],
      "source": [
        "from gymnasium import Env, spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6cwdwrFHEeIk"
      },
      "outputs": [],
      "source": [
        "#@title Create directories to hold models and logs\n",
        "model_dir = \"models\"\n",
        "log_dir = \"logs\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGBmuh2DE6eB"
      },
      "source": [
        "# Training and testing function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heRI_ExiEtf5"
      },
      "outputs": [],
      "source": [
        "def train_model(env, sb3_algo, max_iter = 10, env_name = ''):\n",
        "    if sb3_algo=='SAC':\n",
        "        model = SAC('MlpPolicy', env, verbose=1, device='cuda', tensorboard_log=log_dir)\n",
        "    elif sb3_algo=='TD3':\n",
        "        model = TD3('MlpPolicy', env, verbose=1, device='cuda', tensorboard_log=log_dir)\n",
        "    elif sb3_algo=='A2C':\n",
        "        model = A2C('MlpPolicy', env, verbose=1, device='cuda', tensorboard_log=log_dir)\n",
        "    else:\n",
        "        print('Algorithm not found')\n",
        "        return\n",
        "\n",
        "    TIMESTEPS = 25000\n",
        "    iters = 0\n",
        "    while True:\n",
        "        iters += 1\n",
        "\n",
        "        model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False)\n",
        "        model.save(f\"{model_dir}/{sb3_algo}_{env_name}_{TIMESTEPS*iters}\")\n",
        "\n",
        "        if iters>=max_iter:\n",
        "          break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOrir3cPEvk9"
      },
      "outputs": [],
      "source": [
        "def test_model(env, sb3_algo, path_to_model, extra_steps = 500):\n",
        "\n",
        "    if sb3_algo=='SAC':\n",
        "        model = SAC.load(path_to_model, env=env)\n",
        "    elif sb3_algo=='TD3':\n",
        "        model = TD3.load(path_to_model, env=env)\n",
        "    elif sb3_algo=='A2C':\n",
        "        model = A2C.load(path_to_model, env=env)\n",
        "    else:\n",
        "        print('Algorithm not found')\n",
        "        return\n",
        "\n",
        "    obs = env.reset()[0]\n",
        "    done = False\n",
        "    while True:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, done, _, _ = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            extra_steps -= 1\n",
        "\n",
        "            if extra_steps < 0:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8IQKl28S8xi"
      },
      "outputs": [],
      "source": [
        "def test_model_simple(env, sb3_algo, path_to_model, extra_steps = 0, seed = None):\n",
        "\n",
        "    if sb3_algo=='SAC':\n",
        "        model = SAC.load(path_to_model, env=env)\n",
        "    elif sb3_algo=='TD3':\n",
        "        model = TD3.load(path_to_model, env=env)\n",
        "    elif sb3_algo=='A2C':\n",
        "        model = A2C.load(path_to_model, env=env)\n",
        "    else:\n",
        "        print('Algorithm not found')\n",
        "        return\n",
        "\n",
        "    obs = env.reset(seed)\n",
        "    done = False\n",
        "    obs_list = [env.render(mode='rgb_array')]\n",
        "    while True:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, terminated, truncated, _ = env.step(action)\n",
        "        obs_list.append(env.render(mode='rgb_array'))\n",
        "\n",
        "        if terminated or truncated:\n",
        "            extra_steps -= 1\n",
        "\n",
        "            if extra_steps < 0:\n",
        "                break\n",
        "    return obs_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZ2JHeqBLt1"
      },
      "source": [
        "# Custom env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "cellView": "form",
        "id": "Cxg0C-WMKaTt"
      },
      "outputs": [],
      "source": [
        "#@title simple_env_for_sbl3 [from:'101 Gym - Creating custom gym env.ipynb']\n",
        "\n",
        "class SimpleEnv4SBL3(Env):\n",
        "  def __init__(self,cnv_sz = 10,obs_factr=0.3,env_seed=0, rwd_choice = 0):\n",
        "    super(SimpleEnv4SBL3, self).__init__()\n",
        "    # Define a 2-D observation space\n",
        "    self.observation_shape = (2,)\n",
        "    self.observation_space = spaces.Box(low = np.zeros(self.observation_shape),\n",
        "                                        high = np.ones(self.observation_shape),\n",
        "                                        dtype = np.float16)\n",
        "\n",
        "    # Define an action space ranging from 0 to 4\n",
        "    action_shape = (1,)\n",
        "    self.action_space = spaces.Box(low = np.zeros(action_shape),\n",
        "                                        high = 4*np.ones(action_shape),\n",
        "                                        dtype = np.float16)\n",
        "\n",
        "    self.env_seed = env_seed\n",
        "    self.obs_factr = obs_factr\n",
        "    self.cnv_sz = cnv_sz\n",
        "    self.rwd_choice = rwd_choice\n",
        "\n",
        "    # Reset\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self, seed=None):\n",
        "\n",
        "    # Env\n",
        "    np.random.seed(self.env_seed)\n",
        "    #   - we will leave the bottom right corner for goal and keep it obstacle free\n",
        "    #   - self._goal_state = (self.cnv_sz-1,self.cnv_sz-1) # tuple(np.random.choice(np.arange(self.cnv_sz),2))\n",
        "    # > goal\n",
        "    if np.random.uniform(0,1)<=0.5: # 50% probability\n",
        "      self._goal_state = (self.cnv_sz-1, np.random.choice(np.arange(self.cnv_sz),1)[0]) # bottom goal\n",
        "    else:\n",
        "      self._goal_state = (np.random.choice(np.arange(self.cnv_sz),1)[0],self.cnv_sz-1) # right side goal\n",
        "    # > obstacles\n",
        "    all_states_except_few = [(i,j) for i in range(1,self.cnv_sz-1) for j in range(1,self.cnv_sz-1) \\\n",
        "                  if not (i,j) == self._goal_state] # all states except corner and goal (path exists)\n",
        "    total_obs_region = (self.cnv_sz-2)**2-2 # len(all_states_except_few)\n",
        "    no_of_obs = np.floor(self.obs_factr*total_obs_region)\n",
        "    all_states_except_few.pop(0) # <-- remove start point\n",
        "    sel_obs = np.random.choice( np.arange(total_obs_region) ,int(no_of_obs),replace=False)\n",
        "    self._obstacles = [all_states_except_few[i] for i in sel_obs]\n",
        "\n",
        "    # Episode settings\n",
        "    self._max_episode_steps = self.cnv_sz**2 # 2*self.cnv_sz\n",
        "\n",
        "    # State\n",
        "    if seed==0:\n",
        "      self.state = (0,0)\n",
        "    else:\n",
        "      np.random.seed(seed)\n",
        "      self.state = tuple(np.random.choice( np.arange(self.cnv_sz),2 ))\n",
        "\n",
        "    # Steps\n",
        "    self._elapsed_steps = 0\n",
        "\n",
        "    return self.state\n",
        "\n",
        "  def render(self, mode = \"human\"):\n",
        "    assert mode in [\"human\", \"rgb_array\"], \"Invalid mode, must be either \\\"human\\\" or \\\"rgb_array\\\"\"\n",
        "    cnv = np.zeros((self.cnv_sz,self.cnv_sz))\n",
        "    for i,j in self._obstacles:\n",
        "      cnv[i,j] = np.nan\n",
        "    cnv[self.state[0],self.state[1]] = 1\n",
        "    cnv[self._goal_state[0],self._goal_state[1]] = np.inf\n",
        "    if mode == \"human\":\n",
        "      print(f'INFO: The {np.nan} are obstacles and {np.inf} is the goal. Bot starts at (0,0).')\n",
        "      print(cnv)\n",
        "    elif mode == \"rgb_array\":\n",
        "      return cnv\n",
        "\n",
        "  def close(self):\n",
        "    pass\n",
        "\n",
        "  def step(self, action):\n",
        "    info = {}\n",
        "\n",
        "    if np.round(action)==0: # left\n",
        "      move = (0,-1)\n",
        "    elif np.round(action)==1: # right\n",
        "      move = (0,1)\n",
        "    elif np.round(action)==2: # up\n",
        "      move = (-1,0)\n",
        "    elif np.round(action)==3: # down\n",
        "      move = (1,0)\n",
        "    else:\n",
        "      move = (0,0)\n",
        "\n",
        "    self.state = (np.clip(self.state[0] + move[0], 0, self.cnv_sz-1), \\\n",
        "                  np.clip(self.state[1] + move[1], 0, self.cnv_sz-1) )\n",
        "\n",
        "    reward, terminated, truncated = self.reward_design()\n",
        "\n",
        "    return self.state, reward, terminated, truncated, info\n",
        "\n",
        "  def reward_design(self):\n",
        "    reward = 0.\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "\n",
        "    if self.rwd_choice==0: # Exploratory to goal - takes longest path to goal\n",
        "      # If we know how many steps to optimally explore, we can put this number into 'self._max_episode_steps' for efficient exploration.\n",
        "      if self.state == self._goal_state:\n",
        "        reward = self.cnv_sz**2\n",
        "        terminated = True\n",
        "      else:\n",
        "        reward = 1.-np.linalg.norm(np.array(self.state)-np.array(self._goal_state))/self.cnv_sz # positive\n",
        "      for obs_state in self._obstacles:\n",
        "        if self.state == obs_state:\n",
        "          reward = -1.\n",
        "          terminated = True\n",
        "\n",
        "      self._elapsed_steps += 1\n",
        "      if self._elapsed_steps >= self._max_episode_steps:\n",
        "        truncated = True\n",
        "\n",
        "    elif self.rwd_choice==1: # Go fast to goal and stay (reward the approach and at goal)\n",
        "      if self.state == self._goal_state:\n",
        "        reward = self.cnv_sz**2\n",
        "      else:\n",
        "        reward = 1.-np.linalg.norm(np.array(self.state)-np.array(self._goal_state))/self.cnv_sz # positive\n",
        "      for obs_state in self._obstacles:\n",
        "        if self.state == obs_state:\n",
        "          reward = -1.\n",
        "          terminated = True\n",
        "\n",
        "      self._elapsed_steps += 1\n",
        "      if self._elapsed_steps >= self._max_episode_steps:\n",
        "        truncated = True\n",
        "\n",
        "    elif self.rwd_choice==2: # Go fast to goal and end (reward the approach <= penalize the time)\n",
        "      if self.state == self._goal_state:\n",
        "        reward = self.cnv_sz**2\n",
        "        terminated = True\n",
        "      else:\n",
        "        reward = -np.linalg.norm(np.array(self.state)-np.array(self._goal_state))/self.cnv_sz # negative\n",
        "      for obs_state in self._obstacles:\n",
        "        if self.state == obs_state:\n",
        "          reward = -self.cnv_sz**2. # should be large\n",
        "          terminated = True\n",
        "\n",
        "      self._elapsed_steps += 1\n",
        "      if self._elapsed_steps >= self._max_episode_steps:\n",
        "        truncated = True\n",
        "\n",
        "    return reward, terminated, truncated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOsFYQyP_3g5"
      },
      "source": [
        "# Training and Testing SBL3 on custom model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5GQv5qC83Sw"
      },
      "source": [
        "## ENV case 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6QxCnLyrzKxd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: The nan are obstacles and inf is the goal. Bot starts at (0,0).\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. nan  0. nan  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. nan nan  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0. nan  0.]\n",
            " [ 0.  0.  0.  0. nan  0. nan nan  0.  0.]\n",
            " [ 0. nan  0. nan nan nan  0.  0.  0. inf]\n",
            " [ 0.  0. nan  0.  0.  1.  0. nan  0.  0.]\n",
            " [ 0. nan  0.  0.  0.  0.  0. nan nan  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/som/.local/lib/python3.8/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float16, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/home/som/.local/lib/python3.8/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float16, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        }
      ],
      "source": [
        "#@title Test env 1\n",
        "\n",
        "nwenv = SimpleEnv4SBL3()\n",
        "nwenv.reset()\n",
        "nwenv.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yIL2OsJSIoPK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "<< Control sequence ID: go_goal >>\n",
            "Start point: (0,0)\n",
            "The state is (5, 9) and the goal is (5, 9).\n",
            "Reached goal!\n",
            "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0. nan  0. nan  0.  0.  0.]\n",
            " [ 1.  0.  0.  0. nan nan  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.  0. nan  0.]\n",
            " [ 1.  0.  0.  0. nan  0. nan nan  0.  0.]\n",
            " [ 1. nan  0. nan nan nan  0.  0.  0. inf]\n",
            " [ 1.  0. nan  0.  0. nan  0. nan  0.  1.]\n",
            " [ 1. nan  0.  0.  0.  0.  0. nan nan  1.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
            "\n",
            "<< Control sequence ID: go_random >>\n",
            "Start point: random\n",
            "The state is (2, 4) and the goal is (5, 9).\n",
            "Fell into abyss!\n",
            "[[ 1.  3.  2.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  3.  2.  1. nan  0. nan  0.  0.  0.]\n",
            " [ 1.  1.  0.  1. nan nan  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0. nan  0.]\n",
            " [ 0.  0.  0.  0. nan  0. nan nan  0.  0.]\n",
            " [ 0. nan  0. nan nan nan  0.  0.  0. inf]\n",
            " [ 0.  0. nan  0.  0. nan  0. nan  0.  0.]\n",
            " [ 0. nan  0.  0.  0.  0.  0. nan nan  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            "<< Control sequence ID: go_circle >>\n",
            "Start point: (0,0)\n",
            "Too many steps taken!\n",
            "[[26. 25.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [25. 25.  0.  0. nan  0. nan  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. nan nan  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0. nan  0.]\n",
            " [ 0.  0.  0.  0. nan  0. nan nan  0.  0.]\n",
            " [ 0. nan  0. nan nan nan  0.  0.  0. inf]\n",
            " [ 0.  0. nan  0.  0. nan  0. nan  0.  0.]\n",
            " [ 0. nan  0.  0.  0.  0.  0. nan nan  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Test env 1 actions\n",
        "action_list1 = [3 for _ in range(nwenv.cnv_sz-1)] + [1 for _ in range(nwenv.cnv_sz-1)] \\\n",
        "              + [2 for _ in range(nwenv.cnv_sz-1)]\n",
        "action_list2 = np.random.choice(np.arange(4), 30)\n",
        "action_list3 = [1,3,0,2]*26\n",
        "action_sequences = {'go_goal':action_list1, 'go_random':action_list2, 'go_circle':action_list3}\n",
        "reward_dict = dict()\n",
        "for key in action_sequences.keys():\n",
        "  print(f'\\n<< Control sequence ID: {key} >>')\n",
        "  if key=='go_random':\n",
        "    nwenv.reset()\n",
        "    print('Start point: random')\n",
        "  else:\n",
        "    nwenv.reset(seed=0)\n",
        "    print('Start point: (0,0)')\n",
        "  rwd_seq = [0.]\n",
        "  cnv_traj = nwenv.render(mode='rgb_array')\n",
        "  for action in action_sequences[key]:\n",
        "    _,rwd,tnt,tnc,_ = nwenv.step( action )\n",
        "    rwd_seq.append(rwd_seq[-1] + rwd)\n",
        "    cnv = nwenv.render(mode='rgb_array')\n",
        "    cnv_traj += np.array(cnv)\n",
        "    if tnt:\n",
        "      print(f'The state is {nwenv.state} and the goal is {nwenv._goal_state}.')\n",
        "      if nwenv.state != nwenv._goal_state:\n",
        "        print('Fell into abyss!')\n",
        "      else:\n",
        "        print('Reached goal!')\n",
        "      break\n",
        "    if tnc:\n",
        "      print('Too many steps taken!')\n",
        "      break\n",
        "  reward_dict[key] = rwd_seq\n",
        "  print(cnv_traj)\n",
        "  plt.plot(rwd_seq,label=key)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8RwLx0xBZfJ"
      },
      "outputs": [],
      "source": [
        "gymenv = SimpleEnv4SBL3()\n",
        "SBL3_DRL_NAME = 'SAC' # TD3, etc.\n",
        "max_iter = 10\n",
        "train_model(gymenv, SBL3_DRL_NAME, max_iter = max_iter, env_name='SimpleEnv4SBL3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyRLMkSXKX5w"
      },
      "outputs": [],
      "source": [
        "cnv_list = test_model_simple(gymenv, SBL3_DRL_NAME, f'models/SAC_SimpleEnv4SBL3_{max_iter*25000}', seed=0)\n",
        "cnv_traj = np.array(cnv_list[0])\n",
        "for cnv in cnv_list[1:]:\n",
        "  cnv_traj += np.array(cnv)\n",
        "print(cnv_traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592JmfWL87Lr"
      },
      "source": [
        "## ENV case 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrqeRT8Z8-Xh"
      },
      "outputs": [],
      "source": [
        "#@title Test env 1\n",
        "\n",
        "nwenv = SimpleEnv4SBL3(cnv_sz=18,obs_factr=0.2,env_seed=1)\n",
        "nwenv.reset()\n",
        "nwenv.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryIW1APV9ET0"
      },
      "outputs": [],
      "source": [
        "gymenv = SimpleEnv4SBL3()\n",
        "SBL3_DRL_NAME = 'SAC' # TD3, etc.\n",
        "max_iter = 1000\n",
        "train_model(gymenv, SBL3_DRL_NAME, max_iter = max_iter, env_name='SimpleEnv4SBL3_case2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd3_BU6B9ET2"
      },
      "outputs": [],
      "source": [
        "cnv_list = test_model_simple(gymenv, SBL3_DRL_NAME, f'models/SAC_SimpleEnv4SBL3_{max_iter*25000}', seed=0)\n",
        "cnv_traj = np.array(cnv_list[0])\n",
        "for cnv in cnv_list[1:]:\n",
        "  cnv_traj += np.array(cnv)\n",
        "print(cnv_traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jZyqEqdyg6j"
      },
      "source": [
        "# Reward design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGm6Sf9s9v_p"
      },
      "source": [
        "### Reward type 2 - Go goal fast and stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clsdu1gJ9v_q"
      },
      "outputs": [],
      "source": [
        "#@title Test env 1\n",
        "\n",
        "gymenv = SimpleEnv4SBL3(cnv_sz=8,obs_factr=0.2,env_seed=1,rwd_choice=2)\n",
        "gymenv.reset()\n",
        "gymenv.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir2NNCGe9v_r"
      },
      "outputs": [],
      "source": [
        "SBL3_DRL_NAME = 'SAC' # TD3, etc.\n",
        "max_iter = 20\n",
        "train_model(gymenv, SBL3_DRL_NAME, max_iter = max_iter, env_name='SimpleEnv4SBL3_rwdtype2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOsCMzFg9v_r"
      },
      "outputs": [],
      "source": [
        "# saved_pathfile_name = 'models/SAC_SimpleEnv4SBL3_rwdtype2_500000'\n",
        "saved_pathfile_name = f'models/SAC_SimpleEnv4SBL3_rwdtype2_{max_iter*25000}'\n",
        "cnv_list = test_model_simple(gymenv, SBL3_DRL_NAME, saved_pathfile_name, seed=0)\n",
        "cnv_traj = np.array(cnv_list[0])\n",
        "for cnv in cnv_list[1:]:\n",
        "  cnv_traj += np.array(cnv)\n",
        "print(cnv_traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1. -1.]\n",
            " [-1. -1.]\n",
            " [-1. -1.]\n",
            " [-1.  5.]\n",
            " [-1. -1.]]\n",
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "rwd = -1*np.ones((5,2))\n",
        "rwd[3,1] = 5\n",
        "rwd[0,0] = 1\n",
        "print(rwd)\n",
        "\n",
        "Q_table = np.zeros((5,2))\n",
        "print(Q_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "\n",
        "# Initialize the environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "alternate = False\n",
        "\n",
        "# Set hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.99  # Discount factor\n",
        "epsilon = 1.0  # Exploration rate\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.01\n",
        "num_episodes = 1000\n",
        "max_steps = 100\n",
        "\n",
        "# Initialize Q-table\n",
        "state_space_size = env.observation_space.shape[0]\n",
        "action_space_size = env.action_space.n\n",
        "Q_table = np.zeros((state_space_size, action_space_size))\n",
        "\n",
        "# Discretize the state space\n",
        "def discretize_state(state):\n",
        "    bins = np.linspace(-1, 1, state_space_size)\n",
        "    return tuple(np.digitize(state, bins))\n",
        "\n",
        "# Q-learning algorithm\n",
        "for episode in range(num_episodes):\n",
        "    state = discretize_state(env.reset()[0])\n",
        "    total_reward = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()  # Explore\n",
        "        else:\n",
        "            action = np.argmax(Q_table[state])  # Exploit\n",
        "\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        next_state = discretize_state(next_state)\n",
        "\n",
        "        # Update Q-value\n",
        "        best_next_action = np.argmax(Q_table[next_state])\n",
        "        Q_table[state][action] = (1 - alpha) * Q_table[state][action] \\\n",
        "            + alpha * (reward + gamma * Q_table[next_state][best_next_action]) \n",
        "        \n",
        "        if alternate:\n",
        "            Q_table[state][action] = Q_table[state][action]\\\n",
        "                + alpha * (reward + gamma * Q_table[next_state][best_next_action] - Q_table[state][action]) \n",
        "            \n",
        "            # In DQN - Q-table is replaced by a neural network\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Decay epsilon\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "    print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discretize the state space\n",
        "def discretize_state(state, state_space_size):\n",
        "    bins = np.linspace(-1, 1, state_space_size)\n",
        "    return tuple(np.digitize(state, bins))\n",
        "\n",
        "# Update the agent to use the external discretize_state function\n",
        "class QLearningAgent:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01, num_episodes=1000, max_steps=100, use_external_discretize=True):\n",
        "        self.env = env\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.num_episodes = num_episodes\n",
        "        self.max_steps = max_steps\n",
        "        self.state_space_size = env.observation_space.shape[0]\n",
        "        self.action_space_size = env.action_space.n\n",
        "        self.Q_table = np.zeros((self.state_space_size, self.action_space_size))\n",
        "        self.use_external_discretize = use_external_discretize\n",
        "\n",
        "    def discretize_state(self, state):\n",
        "        return state\n",
        "\n",
        "    def train(self):\n",
        "        for episode in range(self.num_episodes):\n",
        "            if self.use_external_discretize:\n",
        "                state = discretize_state(self.env.reset()[0], self.state_space_size)\n",
        "            else:\n",
        "                state = self.discretize_state(self.env.reset()[0])\n",
        "            total_reward = 0\n",
        "\n",
        "            for step in range(self.max_steps):\n",
        "                if np.random.rand() < self.epsilon:\n",
        "                    action = self.env.action_space.sample()  # Explore\n",
        "                else:\n",
        "                    action = np.argmax(self.Q_table[state])  # Exploit\n",
        "\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                if self.use_external_discretize:\n",
        "                    next_state = discretize_state(next_state, self.state_space_size)\n",
        "                else:\n",
        "                    next_state = self.discretize_state(next_state)\n",
        "\n",
        "                # Update Q-value\n",
        "                best_next_action = np.argmax(self.Q_table[next_state])\n",
        "                self.Q_table[state][action] = (1 - self.alpha) * self.Q_table[state][action] \\\n",
        "                    + self.alpha * (reward + self.gamma * self.Q_table[next_state][best_next_action])\n",
        "\n",
        "                state = next_state\n",
        "                total_reward += reward\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            # Decay epsilon\n",
        "            if self.epsilon > self.epsilon_min:\n",
        "                self.epsilon *= self.epsilon_decay\n",
        "\n",
        "            print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "        self.env.close()\n",
        "\n",
        "# Initialize the environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Create and train the Q-learning agent\n",
        "agent = QLearningAgent(env)\n",
        "agent.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_52slGiBKew"
      },
      "source": [
        "# Ends"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QD7W5cyOEmjt",
        "ekllGKpaxhgu",
        "rOsFYQyP_3g5",
        "U5GQv5qC83Sw",
        "592JmfWL87Lr"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
